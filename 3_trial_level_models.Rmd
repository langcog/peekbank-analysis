---
title: "Trial analysis 3: modeling individual trials"
author: "Mike"
date: "6/26/2022"
output: html_document
---

```{r setup, echo = FALSE}
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lme4))
# suppressPackageStartupMessages(library(ggpmisc))
suppressPackageStartupMessages(library(ggrepel))
suppressPackageStartupMessages(library(ggthemes))
suppressPackageStartupMessages(library(cowplot))
# suppressPackageStartupMessages(library(tidymodels))
# suppressPackageStartupMessages(library(multilevelmod))
# suppressPackageStartupMessages(library(dotwhisker))
# suppressPackageStartupMessages(library(broom))
# suppressPackageStartupMessages(library(broom.mixed))

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, cache = TRUE, 
                      message=FALSE, warning=FALSE, error=FALSE)

load(file = here("data","d_trial.Rds"))
```

Our goal here is to model trial-level variation in accuracy for familiar word recognition across all the experiments in Peekbank. 

Let's move forward with ALL THE DATA (tm). Window will be something like 500 -- 4000 based on the above analysis (which is incomplete, but which suggested that using all the data was better than not).

```{r}
df <- d_trial |>
    filter(t_norm > 500, t_norm < 4000) |>
    group_by(dataset_name, dataset_id, administration_id, 
             age, stimulus_id, target_label, distractor_label) |>
    summarise(accuracy = mean(correct[t_norm > 0], na.rm=TRUE),
              prop_data = mean(!is.na(correct[t_norm > 0])), 
              target = sum(correct[t_norm > 0], na.rm=TRUE),
              distractor = sum(!correct[t_norm > 0], na.rm=TRUE), 
              elogit = log( (target + .5) / (distractor + .5) )) 
df <- df[complete.cases(df),]
```

# Descriptives

How much data is there? 

```{r}
df %>%
  group_by(dataset_name) %>%
  count() %>%
  arrange(desc(n)) %>%
  knitr::kable()
```

```{r}
df %>%
  group_by(target_label) %>%
  count() %>%
  arrange(desc(n)) %>%
  DT::datatable()
```


# The dependent variable

How are we going to model accuracies? The trouble is that we have a very odd dependent variable. 

```{r}
ggplot(df, aes(x = accuracy)) + 
  geom_histogram()
```



```{r}
ggplot(df, aes(x = log(accuracy))) + 
  geom_histogram()
```

What about going back to the raw proportions? 

```{r}
ggplot(df, aes(x = elogit)) + 
  geom_histogram()
```

And consider filtering 0/1 observations just to see if we can get a decent distribution.

```{r}
ggplot(filter(df, accuracy > 0, accuracy < 1), 
       aes(x = elogit)) + 
  geom_histogram()
```
That looks lovely. 

```{r}
df_clean <- filter(df, accuracy > 0, accuracy < 1)
```

# Target for modeling

Plot all trials by all participants.

```{r}
ggplot(df_clean, aes(x = age/12, y = elogit)) + 
  geom_point(alpha = .01) + 
  geom_smooth() + 
  geom_hline(lty = 2, yintercept = 0) + 
  ggthemes::theme_few()
```

Try breaking this down by word.

```{r}
words <- df_clean |>
  group_by(target_label) |> 
  count() 
  
hf_words <- words |>
  filter(n > 200)

comparison_plot <- ggplot(filter(df_clean, target_label %in% hf_words$target_label),
       aes(x = age/12, y = elogit, col = target_label)) + 
  geom_jitter(alpha = .05, width = .02, height = 0) + 
  geom_smooth(se=FALSE) + 
  geom_hline(lty = 2, yintercept = 0)+ 
  ggthemes::theme_few()
comparison_plot
```


# Model comparison 

What follows is an iterative model building/comparison exercise. The goal is really to build up something that is interpretable as a model of variation in the LWL task. You might think this could be done programmatically as opposed to with cut-and-paste as I did it here. In my defense, I spent a lot of time with `tidymodels` and `workflows` and found that there were some bugs in the `predict` workflow that were insurmountable for `lme4`. In particular, we couldn't predict with different random effect structures, meaning that one critical function that we were trying to fulfill here was not doable under `tidymodels`. Fail. Hence the copy/paste. 


```{r}
lmm_fit <- lmer(elogit ~ age + 
                  (1 | administration_id), 
                data = df_clean)

preds <- expand_grid(
  age = seq(min(df_clean$age), max(df_clean$age),1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  0, 
                         newdata = preds))

ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_smooth() + 
  geom_line(data = preds, 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few() 
```

Now let's put in some random effects. 

```{r}
lmm_fit <- lmer(elogit ~ age + 
                  (1 | administration_id) + 
                  (1 | dataset_name) + 
                  (1 | target_label), 
                data = df_clean)

preds <- expand_grid(
  age = seq(min(df_clean$age),max(df_clean$age),1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  (1|target_label), 
                         newdata = preds))

ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = preds, 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few() +
  geom_smooth()

```

Random slopes by age.

```{r}
lmm_fit <- lmer(elogit ~ age + 
                  (1 | administration_id) + 
                  (1 | dataset_name) + 
                  (age | target_label), 
                data = df_clean)

preds <- expand_grid(
  age = seq(min(df_clean$age),max(df_clean$age),1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  (age|target_label), 
                         newdata = preds))

main_plot <- ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = preds, 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few() 

plot_grid(main_plot + scale_color_discrete(guide = "none"), 
          comparison_plot + scale_color_discrete(guide = "none"))
```

Seems like we should try to accommodate the curvature in the age slopes. One possibility is to consider `log(age)` as a predictor. We will center age to increase convergence and swap to `bobyqa` optimizer. 

```{r}
df_clean$log_age <- log(df_clean$age)
df_clean$log_age_centered <- df_clean$log_age - mean(df_clean$log_age)

lmm_fit <- lmer(elogit ~ log_age_centered + 
                  (1 | administration_id) + 
                  (1 | dataset_name) + 
                  (log_age_centered | target_label), 
                data = df_clean, 
                control = lmerControl(optimizer="bobyqa"))

preds <- expand_grid(
  log_age_centered = seq(min(df_clean$log_age_centered),
                max(df_clean$log_age_centered), .1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(df_clean$log_age)))

main_plot <- ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = preds, 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few()

plot_grid(main_plot + scale_color_discrete(guide = "none"), 
          comparison_plot + scale_color_discrete(guide = "none"))
```

This ends up looking quite good in terms of the shape of the curves and their distribution. Let's look at the random effects. 

```{r}
tibble(ranef(lmm_fit)$target_label) |>
  mutate(target_label = rownames(ranef(lmm_fit)$target_label)) |>
  left_join(words) |>
  rename(intercept = `(Intercept)`) |>
  select(target_label, intercept, log_age_centered, n) |>
  arrange(desc(n)) |>
  filter(n>100) |>
  knitr::kable(digits = 2)
```

I'm worried because these don't look at all like they reflect acquisition ordering. For example, `ball` has a very low slope and intercept. Let's take a look at the top ten of these in the empirical data. 

```{r}
vhf_words = words |>
  filter(n > 800)

ggplot(filter(df_clean, target_label %in% vhf_words$target_label),
       aes(x = age, y = elogit)) + 
  geom_jitter(width = 1, height = 0, alpha = .01) + 
  facet_wrap(~target_label) + 
  geom_smooth(se=TRUE) + 
  scale_color_solarized() +
  geom_hline(lty = 2, yintercept = 0)+ 
  ggthemes::theme_few()
```

Let's zoom in on `ball`.

```{r}
df_clean |>
  ungroup() |>
  filter(target_label == "ball") |>
  group_by(target_label, distractor_label, dataset_name) |>
  summarise(age = mean(age)/12) |>
  arrange(age) |>
  knitr::kable(digits = 1)
```

We see `garrison_bergelson_2020` has lots and lots of different targets. Across datasets, trends definitely go up, but there is confounding across datasets. 

```{r}
ggplot(filter(df_clean, target_label == "ball"),
       aes(x = age, y = elogit, col = dataset_name)) + 
  geom_jitter(width = 1, height = 0, alpha = .1) + 
  geom_smooth(method = "lm", se=FALSE) + 
  geom_hline(lty = 2, yintercept = 0)+ 
  ggthemes::theme_few()
```

First, we should probably model within-dataset age effects. Second, we should probably model the distractors. 

Our model of distractors right now is purely linear. Some distractors are harder -- such that if having `car` as the distractor makes you less likely to look at the target, then it's going to have a negative coefficient. Similarly, maybe `ball` is a boring distractor and so you're more likely to look. We can't fit in age-slopes though. 

```{r}
lmm_fit <- lmer(elogit ~ log_age_centered + 
                  (1 | administration_id) + 
                  (log_age_centered | dataset_name) + 
                  (log_age_centered | target_label) + 
                  (1 | distractor_label), 
                data = df_clean, 
                control = lmerControl(optimizer="bobyqa"))

preds <- expand_grid(
  log_age_centered = seq(min(df_clean$log_age_centered),
                max(df_clean$log_age_centered), .1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(df_clean$log_age)))

main_plot <- ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = preds, 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few()

plot_grid(main_plot + scale_color_discrete(guide = "none"), 
          comparison_plot + scale_color_discrete(guide = "none"))
```

Let's look at the random effects one more time and see if this helps.

```{r}
target_ranef <-  tibble(ranef(lmm_fit)$target_label) |>
  mutate(target_label = rownames(ranef(lmm_fit)$target_label)) |>
  left_join(words) |>
  rename(intercept = `(Intercept)`) |>
  select(target_label, intercept, log_age_centered, n) 

target_ranef |>
  arrange(desc(n)) |>
  filter(n>100) |>
  knitr::kable(digits = 2)
```

It looks like the coefficients for `ball` are regularized more toward zero though probably not completely so. That makes me think that we are probably indexing a bunch of salience effects as well as true word recognition. 

Just for kicks, let's look at the distractors as well. 

```{r}
distractors <- df_clean |>
  group_by(distractor_label) |>
  count() 

distractor_ranef <- tibble(ranef(lmm_fit)$distractor_label) |>
  mutate(distractor_label = rownames(ranef(lmm_fit)$distractor_label)) |>
  left_join(distractors) |>
  rename(intercept = `(Intercept)`) |>
  select(distractor_label, intercept,  n) 

distractor_ranef |>
  arrange(desc(n)) |>
  filter(n>100) |>
  knitr::kable(digits = 2)
```

This looks like animates are negative (harder) and inanimates are positive (easier) for the most part. 

Let's add a fixed effect for animacy of target and distractor to try and soak up these preference effects systematically. 

```{r}
sort(unique(c(unique(df_clean$target_label),
              unique(df_clean$distractor_label))))

animates <- c("animal","baby","dog","bear","bird","boy", 
              "bunny","cat","chicken","cow","dog","duck","elephant",
              "fish","frog","giraffe","horse","kangaroo","lion","monkey",
              "owl","pig","puppy","sheep","teddy","tiger","whale","zebra")

df_clean$animate_target <- df_clean$target_label %in% animates
df_clean$animate_distractor <- df_clean$distractor_label %in% animates
```
Now let's add animacy of targets and distractor to the model as well as interactions with age. 

```{r}
lmm_fit <- lmer(elogit ~ log_age_centered * animate_target + 
                  log_age_centered * animate_distractor +
                  (1 | administration_id) + 
                  (log_age_centered | dataset_name) + 
                  (log_age_centered | target_label) + 
                  (1 | distractor_label), 
                data = df_clean, 
                control = lmerControl(optimizer="bobyqa"))

preds <- expand_grid(
  animate_target = c(TRUE, FALSE), 
  animate_distractor = c(TRUE, FALSE), 
  log_age_centered = seq(min(df_clean$log_age_centered),
                max(df_clean$log_age_centered), .1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(df_clean$log_age)))

main_plot <- ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = filter(preds, !animate_target, !animate_distractor), 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few()

plot_grid(main_plot + scale_color_discrete(guide = "none"), 
          comparison_plot + scale_color_discrete(guide = "none"))
```

Now when we make predictions, we need to make the predictions with or without these animacy effects. It's kind of funny to look at a "dog" prediction with `animate_target=FALSE` but that's really like saying "what's the predicted curve for dog knowledge independent of perceptual biases." Let's look at the model fits first, and then the random effects.

```{r}
knitr::kable(summary(lmm_fit)[[10]], digits = 2)
```

We can see that there is a pretty sizable effect for each, such that:

1. with an animate target, there is a positive effect on accuracy (animate bias)
2. with an animate distractor, there is a negative effect on accuracy (animate bias again)
3. the animate target bias decreases with log age, so it's bigger for younger kids
4. the animate distractor bias increases (becomes less negative) with log age, so it's also bigger for younger kids

So in sum, there are big animate biases, especially for younger kids. That seems really important.  

Tried fitting an interaction (animate target X animate distractor) to see if they canceled out but the effect was negligible. 

Let's see how the word-level random effects look now. Really they are quite different!

```{r}
target_ranef <-  tibble(ranef(lmm_fit)$target_label) |>
  mutate(target_label = rownames(ranef(lmm_fit)$target_label)) |>
  left_join(words) |>
  rename(intercept = `(Intercept)`) |>
  select(target_label, intercept, log_age_centered, n) 

target_ranef |>
  arrange(desc(intercept)) |>
  filter(n>100) |>
  knitr::kable(digits = 2)
```

Let's save the resulting model and carry it forward. 

```{r}
save(file = here("data","df_clean.Rds"), df_clean)
save(file = here("data","lmm_fit.Rds"), lmm_fit)
```

## Some model plots

```{r}
preds <- expand_grid(
  animate_target = c(TRUE, FALSE), 
  animate_distractor = c(TRUE, FALSE), 
  log_age_centered = seq(min(df_clean$log_age_centered),
                max(df_clean$log_age_centered), .1))

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = NA, 
                         newdata = preds), 
         age = exp(log_age_centered + mean(df_clean$log_age)))

# animate_plot <- 
  ggplot(df_clean,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = preds, 
            aes(y = .pred, col = animate_target, lty = animate_distractor), 
            size = 1.5) + 
  geom_hline(lty = 2, yintercept = 0) + 
  scale_x_continuous(breaks = c(12,24,36,48,60)) + 
  scale_color_solarized(name = "Animate target") + 
  scale_linetype(name = "Animate distractor") + 
  ylab("Trial-level accuracy (elogit)") + 
  xlab("Age (months)") + 
  ggthemes::theme_few()

# ggsave(plot =animate_plot, filename = "~/Desktop/animate.pdf", height = 4, width = 6)
```


# Baseline correction

Let's try trial-by-trial baseline correction. 

```{r}
hist(d_trial$t_norm)
```


```{r}
df_bc <- d_trial |>
    # filter(t_norm > 500, t_norm < 4000) |>
    group_by(dataset_name, dataset_id, administration_id, 
             age, stimulus_id, target_label, distractor_label) |>
    summarise(accuracy = mean(correct[t_norm > 500 & t_norm < 4000], na.rm=TRUE),
              prop_data = mean(!is.na(correct[t_norm > 500 & t_norm < 4000])), 
              target = sum(correct[t_norm > 500 & t_norm < 4000], na.rm=TRUE),
              target_baseline = sum(correct[t_norm <= 200], na.rm=TRUE),
              distractor = sum(!correct[t_norm > 500 & t_norm < 4000], na.rm=TRUE), 
              distractor_baseline = sum(!correct[t_norm <= 200], na.rm=TRUE), 
              elogit_baseline = log( (target_baseline + .5) / 
                              (distractor_baseline + .5) ),
              elogit = log( (target + .5) / 
                              (distractor + .5) ), 
              elogit_bc = elogit - elogit_baseline) 
df_bc <- df_bc[complete.cases(df_bc),]
df_clean_bc <- filter(df_bc, accuracy > 0, accuracy < 1, elogit_baseline < 4, elogit_baseline > -4)
```

```{r}
ggplot(df_clean_bc, aes(x = elogit)) + 
  geom_histogram()
ggplot(df_clean_bc, aes(x = elogit_baseline)) + 
  geom_histogram()
ggplot(df_clean_bc, aes(x = elogit_bc)) + 
  geom_histogram()

```


# Target for modeling

Plot all trials by all participants.

```{r}
ggplot(df_clean_bc, aes(x = age/12, y = elogit_bc)) + 
  geom_point(alpha = .01) + 
  geom_smooth() + 
  geom_hline(lty = 2, yintercept = 0) + 
  ggthemes::theme_few()
```

```{r}
df_clean_bc$log_age <- log(df_clean_bc$age)
df_clean_bc$log_age_centered <- df_clean_bc$log_age - mean(df_clean_bc$log_age)

df_clean_bc$animate_target <- df_clean_bc$target_label %in% animates
df_clean_bc$animate_distractor <- df_clean_bc$distractor_label %in% animates

lmm_fit_bc <- lmer(elogit_bc ~ log_age_centered * animate_target + 
                  log_age_centered * animate_distractor +
                  (1 | administration_id) + 
                  (log_age_centered | dataset_name) + 
                  (log_age_centered | target_label) + 
                  (1 | distractor_label), 
                data = df_clean_bc, 
                control = lmerControl(optimizer="bobyqa"))

preds <- expand_grid(
  animate_target = c(TRUE, FALSE), 
  animate_distractor = c(TRUE, FALSE), 
  log_age_centered = seq(min(df_clean_bc$log_age_centered),
                max(df_clean_bc$log_age_centered), .1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit_bc, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(df_clean_bc$log_age)))

ggplot(df_clean_bc,
       aes(x = age, y = elogit)) + 
  geom_point(alpha = .1) + 
  geom_line(data = filter(preds, !animate_target, !animate_distractor), 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few()

```



```{r}
target_ranef <-  tibble(ranef(lmm_fit)$target_label) |>
  mutate(target_label = rownames(ranef(lmm_fit)$target_label)) |>
  left_join(words) |>
  rename(intercept = `(Intercept)`) |>
  select(target_label, intercept, log_age_centered, n) 

target_ranef |>
  arrange(desc(intercept)) |>
  filter(n>100) |>
  knitr::kable(digits = 2)
```


Now look at baseline. 

```{r}
df_clean_bc$log_age <- log(df_clean_bc$age)
df_clean_bc$log_age_centered <- df_clean_bc$log_age - mean(df_clean_bc$log_age)

df_clean_bc$animate_target <- df_clean_bc$target_label %in% animates
df_clean_bc$animate_distractor <- df_clean_bc$distractor_label %in% animates

lmm_fit <- lmer(elogit_baseline ~ log_age_centered * animate_target + 
                  log_age_centered * animate_distractor +
                  (1 | administration_id) + 
                  (log_age_centered | dataset_name) + 
                  (log_age_centered | target_label) + 
                  (1 | distractor_label), 
                data = df_clean_bc, 
                control = lmerControl(optimizer="bobyqa"))

preds <- expand_grid(
  animate_target = c(TRUE, FALSE), 
  animate_distractor = c(TRUE, FALSE), 
  log_age_centered = seq(min(df_clean_bc$log_age_centered),
                max(df_clean_bc$log_age_centered), .1),
  target_label = hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(lmm_fit, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(df_clean_bc$log_age)))

ggplot(df_clean_bc,
       aes(x = age, y = elogit_baseline)) + 
  geom_point(alpha = .1) + 
  geom_line(data = filter(preds, !animate_target, !animate_distractor), 
            aes(x = age, y = .pred, col = target_label)) + 
  geom_hline(lty = 2, yintercept = 0) + 
  xlab("Age (months)") + 
  ggthemes::theme_few()

```

```{r}
save(file = here("data","df_clean_bc.Rds"), df_clean_bc)
save(file = here("data","lmm_fit_bc.Rds"), lmm_fit_bc)
```

